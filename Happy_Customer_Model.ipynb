{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic and Delivery : Happy Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description:\n",
    "Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers.\n",
    "\n",
    "X1 = my order was delivered on time.\n",
    "\n",
    "X2 = contents of my order was as I expected.\n",
    "\n",
    "X3 = I ordered everything I wanted to order.\n",
    "\n",
    "X4 = I paid a good price for my order.\n",
    "\n",
    "X5 = I am satisfied with my courier.\n",
    "\n",
    "X6 = the app makes ordering easy for me.\n",
    "\n",
    "Attributes X1 to X6 indicate the responses for each question and have values from 1 to 5 where the smaller number indicates less and the higher number indicates more towards the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal(s):\n",
    "\n",
    "Predict if a customer is happy or not based on the answers they give to questions asked.\n",
    "\n",
    "Success Metrics:\n",
    "\n",
    "Reach 73% accuracy score or above.\n",
    "\n",
    "Find which questions/features are more important when predicting a customerâ€™s happiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data processing and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn modules for feature selection and model evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFE, SelectKBest, SelectFromModel, chi2, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# libraries for visualization\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y     int64\n",
      "X1    int64\n",
      "X2    int64\n",
      "X3    int64\n",
      "X4    int64\n",
      "X5    int64\n",
      "X6    int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547619</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.531746</td>\n",
       "      <td>3.309524</td>\n",
       "      <td>3.746032</td>\n",
       "      <td>3.650794</td>\n",
       "      <td>4.253968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.114892</td>\n",
       "      <td>1.023440</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>1.147641</td>\n",
       "      <td>0.809311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Y          X1          X2          X3          X4          X5  \\\n",
       "count  126.000000  126.000000  126.000000  126.000000  126.000000  126.000000   \n",
       "mean     0.547619    4.333333    2.531746    3.309524    3.746032    3.650794   \n",
       "std      0.499714    0.800000    1.114892    1.023440    0.875776    1.147641   \n",
       "min      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000    4.000000    2.000000    3.000000    3.000000    3.000000   \n",
       "50%      1.000000    5.000000    3.000000    3.000000    4.000000    4.000000   \n",
       "75%      1.000000    5.000000    3.000000    4.000000    4.000000    4.000000   \n",
       "max      1.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "               X6  \n",
       "count  126.000000  \n",
       "mean     4.253968  \n",
       "std      0.809311  \n",
       "min      1.000000  \n",
       "25%      4.000000  \n",
       "50%      4.000000  \n",
       "75%      5.000000  \n",
       "max      5.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('ACME-HappinessSurvey2020.csv')\n",
    "\n",
    "# Print datatypes\n",
    "print(df.dtypes)\n",
    "\n",
    "# Describe columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  X1  X2  X3  X4  X5  X6\n",
       "0  0   3   3   3   4   2   4\n",
       "1  0   3   2   3   5   4   3\n",
       "2  1   5   3   3   3   3   5\n",
       "3  0   5   4   3   3   3   5\n",
       "4  0   5   4   3   3   3   5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split feature and target vectors\n",
    "X = df.drop(\"Y\", 1)\n",
    "Y = df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, Y):\n",
    "    '''Use a RLogisticRegression.'''\n",
    "    \n",
    "    # define the model to use\n",
    "    model = RandomForestClassifier(criterion='entropy', random_state=47)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, X_test, Y_test):\n",
    "    '''Get model evaluation metrics on the test set.'''\n",
    "    \n",
    "    # Get model predictions\n",
    "    y_predict_r = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics for assesing performance of the model.\n",
    "    acc = accuracy_score(Y_test, y_predict_r)\n",
    "    roc = roc_auc_score(Y_test, y_predict_r)\n",
    "    prec = precision_score(Y_test, y_predict_r)\n",
    "    rec = recall_score(Y_test, y_predict_r)\n",
    "    f1 = f1_score(Y_test, y_predict_r)\n",
    "    \n",
    "    return acc, roc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get_metrics(X, Y):\n",
    "    '''Train model and get evaluation metrics'''\n",
    "    \n",
    "    # Split train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,stratify=Y, random_state = 123)\n",
    "\n",
    "    # All features of dataset are float values. You normalize all features of the train and test dataset here.\n",
    "    #scaler = StandardScaler().fit(X_train)\n",
    "    #X_train_scaled = scaler.transform(X_train)\n",
    "    #X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Call the fit model function to train the model on the normalized features and the diagnosis values\n",
    "    model = fit_model(X_train, Y_train)\n",
    "\n",
    "    # Make predictions on test dataset and calculate metrics.\n",
    "    acc, roc, prec, rec, f1 = calculate_metrics(model, X_test, Y_test)\n",
    "\n",
    "    return acc, roc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_features(X, Y):\n",
    "    '''Train model and display evaluation metrics.'''\n",
    "    \n",
    "    # Train the model, predict values and get metrics\n",
    "    acc, roc, prec, rec, f1 = train_and_get_metrics(X, Y)\n",
    "\n",
    "    # Construct a dataframe to display metrics.\n",
    "    display_df = pd.DataFrame([[acc, roc, prec, rec, f1, X.shape[1]]], columns=[\"Accuracy\", \"ROC\", \"Precision\", \"Recall\", \"F1 Score\", 'Feature Count'])\n",
    "    \n",
    "    return display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Feature Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy       ROC  Precision    Recall  F1 Score  Feature Count\n",
       "All features  0.653846  0.654762   0.692308  0.642857  0.666667              6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "all_features_eval_df = evaluate_model_on_features(X, Y)\n",
    "all_features_eval_df.index = ['All features']\n",
    "\n",
    "# Initialize results dataframe\n",
    "results = all_features_eval_df\n",
    "\n",
    "# Check the metrics\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Feature Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset features</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy       ROC  Precision    Recall  F1 Score  \\\n",
       "All features     0.653846  0.654762   0.692308  0.642857  0.666667   \n",
       "Subset features  0.730769  0.732143   0.769231  0.714286  0.740741   \n",
       "\n",
       "                 Feature Count  \n",
       "All features                 6  \n",
       "Subset features              4  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the features with high correlation to other features\n",
    "subset_feature_corr_names = [\"X1\",\"X2\",\"X5\", \"X6\"]\n",
    "\n",
    "# Calculate and check evaluation metrics\n",
    "subset_feature_eval_df = evaluate_model_on_features(df[subset_feature_corr_names], Y)\n",
    "subset_feature_eval_df.index = ['Subset features']\n",
    "\n",
    "# Append to results and display\n",
    "results = results.append(subset_feature_eval_df)\n",
    "results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1      X2      X3      X4      X5      X6\n",
      "0  Medium  Medium  Medium    High     Low    High\n",
      "1  Medium     Low  Medium    High    High  Medium\n",
      "2    High  Medium  Medium  Medium  Medium    High\n",
      "3    High    High  Medium  Medium  Medium    High\n",
      "4    High    High  Medium  Medium  Medium    High\n"
     ]
    }
   ],
   "source": [
    "df_features = df[[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\"]]\n",
    "df_features = df_features.replace(1, \"Low\")\n",
    "df_features = df_features.replace(2, \"Low\")\n",
    "df_features = df_features.replace(3, \"Medium\")\n",
    "df_features = df_features.replace(4, \"High\")\n",
    "df_features = df_features.replace(5, \"High\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1_High  X1_Low  X1_Medium  X2_High  X2_Low  X2_Medium  X3_High  X3_Low  \\\n",
      "0        0       0          1        0       0          1        0       0   \n",
      "1        0       0          1        0       1          0        0       0   \n",
      "2        1       0          0        0       0          1        0       0   \n",
      "3        1       0          0        1       0          0        0       0   \n",
      "4        1       0          0        1       0          0        0       0   \n",
      "\n",
      "   X3_Medium  X4_High  X4_Low  X4_Medium  X5_High  X5_Low  X5_Medium  X6_High  \\\n",
      "0          1        1       0          0        0       1          0        1   \n",
      "1          1        1       0          0        1       0          0        0   \n",
      "2          1        0       0          1        0       0          1        1   \n",
      "3          1        0       0          1        0       0          1        1   \n",
      "4          1        0       0          1        0       0          1        1   \n",
      "\n",
      "   X6_Low  X6_Medium  \n",
      "0       0          0  \n",
      "1       0          1  \n",
      "2       0          0  \n",
      "3       0          0  \n",
      "4       0          0  \n"
     ]
    }
   ],
   "source": [
    "LowMedHigh_onehot = pd.get_dummies(df_features)\n",
    "print(LowMedHigh_onehot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Feature Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset features</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowMedHigh_onehot</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy       ROC  Precision    Recall  F1 Score  \\\n",
       "All features       0.653846  0.654762   0.692308  0.642857  0.666667   \n",
       "Subset features    0.730769  0.732143   0.769231  0.714286  0.740741   \n",
       "LowMedHigh_onehot  0.538462  0.541667   0.583333  0.500000  0.538462   \n",
       "\n",
       "                   Feature Count  \n",
       "All features                   6  \n",
       "Subset features                4  \n",
       "LowMedHigh_onehot             18  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate and check evaluation metrics\n",
    "LowMedHigh_onehot_eval_df = evaluate_model_on_features(LowMedHigh_onehot, Y)\n",
    "LowMedHigh_onehot_eval_df.index = ['LowMedHigh_onehot']\n",
    "\n",
    "# Append to results and display\n",
    "results = results.append(LowMedHigh_onehot_eval_df)\n",
    "results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X1     X2     X3     X4     X5     X6\n",
      "0  three  three  three   four    two   four\n",
      "1  three    two  three   five   four  three\n",
      "2   five  three  three  three  three   five\n",
      "3   five   four  three  three  three   five\n",
      "4   five   four  three  three  three   five\n"
     ]
    }
   ],
   "source": [
    "df_features_1to5 = df[[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\"]]\n",
    "df_features_1to5 = df_features_1to5.replace(1, \"one\")\n",
    "df_features_1to5 = df_features_1to5.replace(2, \"two\")\n",
    "df_features_1to5= df_features_1to5.replace(3, \"three\")\n",
    "df_features_1to5 = df_features_1to5.replace(4, \"four\")\n",
    "df_features_1to5 = df_features_1to5.replace(5, \"five\")\n",
    "print(df_features_1to5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1_five  X1_four  X1_one  X1_three  X2_five  X2_four  X2_one  X2_three  \\\n",
      "0        0        0       0         1        0        0       0         1   \n",
      "1        0        0       0         1        0        0       0         0   \n",
      "2        1        0       0         0        0        0       0         1   \n",
      "3        1        0       0         0        0        1       0         0   \n",
      "4        1        0       0         0        0        1       0         0   \n",
      "\n",
      "   X2_two  X3_five  ...  X5_five  X5_four  X5_one  X5_three  X5_two  X6_five  \\\n",
      "0       0        0  ...        0        0       0         0       1        0   \n",
      "1       1        0  ...        0        1       0         0       0        0   \n",
      "2       0        0  ...        0        0       0         1       0        1   \n",
      "3       0        0  ...        0        0       0         1       0        1   \n",
      "4       0        0  ...        0        0       0         1       0        1   \n",
      "\n",
      "   X6_four  X6_one  X6_three  X6_two  \n",
      "0        1       0         0       0  \n",
      "1        0       0         1       0  \n",
      "2        0       0         0       0  \n",
      "3        0       0         0       0  \n",
      "4        0       0         0       0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df_features_1to5_onehot = pd.get_dummies(df_features_1to5)\n",
    "print(df_features_1to5_onehot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Feature Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All features</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset features</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowMedHigh_onehot</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnetoFive_onehot</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy       ROC  Precision    Recall  F1 Score  \\\n",
       "All features       0.653846  0.654762   0.692308  0.642857  0.666667   \n",
       "Subset features    0.730769  0.732143   0.769231  0.714286  0.740741   \n",
       "LowMedHigh_onehot  0.538462  0.541667   0.583333  0.500000  0.538462   \n",
       "OnetoFive_onehot   0.653846  0.654762   0.692308  0.642857  0.666667   \n",
       "\n",
       "                   Feature Count  \n",
       "All features                   6  \n",
       "Subset features                4  \n",
       "LowMedHigh_onehot             18  \n",
       "OnetoFive_onehot              29  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and check evaluation metrics\n",
    "OnetoFive_onehot_eval_df = evaluate_model_on_features(df_features_1to5_onehot, Y)\n",
    "OnetoFive_onehot_eval_df.index = ['OnetoFive_onehot']\n",
    "\n",
    "# Append to results and display\n",
    "results = results.append(OnetoFive_onehot_eval_df)\n",
    "results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
